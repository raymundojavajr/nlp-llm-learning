{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Assignments  \n",
    "**Author:** Raymundo Java Jr.\n",
    "\n",
    "This notebook covers three essential NLP preprocessing assignments:\n",
    "\n",
    "### Assignment 1: Removing Subsequent Occurrence of Words\n",
    "Eliminate adjacent duplicate words to improve clarity and reduce noise.\n",
    "\n",
    "### Assignment 2: Adding Custom Stop Words to `nltk` and `spacy`\n",
    "Extend the default stop word lists with custom words (e.g., \"customword1\", \"customword2\", \"customword3\") for domain-specific text cleaning.\n",
    "\n",
    "### Assignment 3: Stemming\n",
    "Compare stemming techniques (PorterStemmer, LancasterStemmer, SnowballStemmer) using maintenance-related text to determine the best approach for technical documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment -->  Use Case 1: Removing subsequent occurrence of words.\n",
    "\n",
    "Removing subsequent occurrences of words (also known as deduplication of adjacent duplicate words) is a common preprocessing step in NLP. This task is important because: \n",
    "1. Repeated words can distort text analysis, especially in tasks like text summarization, sentiment analysis, and language modeling.\n",
    "2. Removing redundant words improves the readability of the text, making it more coherent.\n",
    "3. Reducing noise in the text data can improve the performance of machine learning models.\n",
    "\n",
    "Input:\n",
    "A single string text that may contain multiple sentences and words. Words are separated by spaces.\n",
    "\n",
    "Output:\n",
    "A single string with subsequent duplicate words removed.\n",
    "\n",
    "Constraints:\n",
    "The input string can be empty.\n",
    "The words are case-sensitive, meaning \"Word\" and \"word\" are considered different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_adjacent_duplicate(text):\n",
    "    \"\"\"Remove adjacent duplicate words from text.\"\"\"\n",
    "    words = text.split()\n",
    "    result = []\n",
    "    for i, word in enumerate(words):\n",
    "        if i == 0 or word != words[i - 1]:\n",
    "            result.append(word)\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Basic duplicate removal\n",
      "Input: The compressor compressor is overheating\n",
      "Output: The compressor is overheating\n",
      "\n",
      "Test: Maintenance redundancy\n",
      "Input: Routine maintenance maintenance is essential for safe operations\n",
      "Output: Routine maintenance is essential for safe operations\n",
      "\n",
      "Test: Engine repair duplication\n",
      "Input: Engine repair repair improves system performance\n",
      "Output: Engine repair improves system performance\n",
      "\n",
      "Test: Case-sensitive check\n",
      "Input: Pump Pump performance is stable\n",
      "Output: Pump performance is stable\n",
      "\n",
      "Test: Mixed uppercase-lowercase words\n",
      "Input: Inspection inspection procedures ensure safety\n",
      "Output: Inspection inspection procedures ensure safety\n",
      "\n",
      "Test: Multiple sentence handling\n",
      "Input: During maintenance, maintenance, safety checks are vital. Safety safety protocols are followed.\n",
      "Output: During maintenance, safety checks are vital. Safety safety protocols are followed.\n",
      "\n",
      "Test: Duplicate phrases in sentences\n",
      "Input: Replacing filters filters improves overall efficiency. Efficiency efficiency boosts performance.\n",
      "Output: Replacing filters improves overall efficiency. Efficiency efficiency boosts performance.\n",
      "\n",
      "Test: Punctuation should not affect word removal\n",
      "Input: Valve! Valve! is critical.\n",
      "Output: Valve! is critical.\n",
      "\n",
      "Test: Comma-separated duplicate words\n",
      "Input: Lubrication, lubrication, is key for operation.\n",
      "Output: Lubrication, lubrication, is key for operation.\n",
      "\n",
      "Test: Empty string case\n",
      "Input: \n",
      "Output: \n",
      "\n",
      "Test: Single word case\n",
      "Input: Overhaul\n",
      "Output: Overhaul\n",
      "\n",
      "Test: Numbers in text\n",
      "Input: System efficiency efficiency is 98% 98%\n",
      "Output: System efficiency is 98%\n",
      "\n",
      "Test: Highly repetitive phrase\n",
      "Input: Maintenance Maintenance Maintenance is crucial\n",
      "Output: Maintenance is crucial\n",
      "\n",
      "Test: Maintenance context redundancy\n",
      "Input: Preventive maintenance preventive maintenance reduces downtime\n",
      "Output: Preventive maintenance preventive maintenance reduces downtime\n",
      "\n",
      "Test: Engine model duplication\n",
      "Input: Engine models models power modern maintenance applications\n",
      "Output: Engine models power modern maintenance applications\n",
      "\n",
      "Test: Equipment inspection redundancy\n",
      "Input: In equipment inspection inspection, identifying faults faults is essential\n",
      "Output: In equipment inspection inspection, identifying faults is essential\n",
      "\n",
      "Test: Long text performance test\n",
      "Input: Operational operational checks and checks improve reliability reliability.\n",
      "Output: Operational operational checks and checks improve reliability reliability.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    (\"The compressor compressor is overheating\", \"Basic duplicate removal\"),\n",
    "    (\n",
    "        \"Routine maintenance maintenance is essential for safe operations\",\n",
    "        \"Maintenance redundancy\",\n",
    "    ),\n",
    "    (\n",
    "        \"Engine repair repair improves system performance\",\n",
    "        \"Engine repair duplication\",\n",
    "    ),\n",
    "    (\"Pump Pump performance is stable\", \"Case-sensitive check\"),\n",
    "    (\n",
    "        \"Inspection inspection procedures ensure safety\",\n",
    "        \"Mixed uppercase-lowercase words\",\n",
    "    ),\n",
    "    (\n",
    "        \"During maintenance, maintenance, safety checks are vital. Safety safety protocols are followed.\",\n",
    "        \"Multiple sentence handling\",\n",
    "    ),\n",
    "    (\n",
    "        \"Replacing filters filters improves overall efficiency. Efficiency efficiency boosts performance.\",\n",
    "        \"Duplicate phrases in sentences\",\n",
    "    ),\n",
    "    (\n",
    "        \"Valve! Valve! is critical.\",\n",
    "        \"Punctuation should not affect word removal\",\n",
    "    ),\n",
    "    (\n",
    "        \"Lubrication, lubrication, is key for operation.\",\n",
    "        \"Comma-separated duplicate words\",\n",
    "    ),\n",
    "    (\"\", \"Empty string case\"),\n",
    "    (\"Overhaul\", \"Single word case\"),\n",
    "    (\"System efficiency efficiency is 98% 98%\", \"Numbers in text\"),\n",
    "    (\"Maintenance Maintenance Maintenance is crucial\", \"Highly repetitive phrase\"),\n",
    "    (\n",
    "        \"Preventive maintenance preventive maintenance reduces downtime\",\n",
    "        \"Maintenance context redundancy\",\n",
    "    ),\n",
    "    (\n",
    "        \"Engine models models power modern maintenance applications\",\n",
    "        \"Engine model duplication\",\n",
    "    ),\n",
    "    (\n",
    "        \"In equipment inspection inspection, identifying faults faults is essential\",\n",
    "        \"Equipment inspection redundancy\",\n",
    "    ),\n",
    "    (\n",
    "        \"Operational operational checks and checks improve reliability reliability.\",\n",
    "        \"Long text performance test\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "for text, description in test_cases:\n",
    "    print(f\"Test: {description}\")\n",
    "    print(f\"Input: {text}\")\n",
    "    print(f\"Output: {remove_adjacent_duplicate(text)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment --> Use Case 2: Adding Custom Stop Words to `nltk` and `spacy`\n",
    "\n",
    "\n",
    "Adding custom stop words is a crucial preprocessing step in NLP. This task is important because:\n",
    "\n",
    "Customizing stop words allows for more flexible and relevant text cleaning tailored to specific use cases.\n",
    "Adding domain-specific stop words improves the performance of text analysis and machine learning models by removing irrelevant terms.\n",
    "Enhances the readability and coherence of the text by eliminating non-essential words.\n",
    "\n",
    "Objective:\n",
    "Extend the default stop words list in both `nltk` and `spacy` by adding custom stop words.\n",
    "\n",
    "Input:\n",
    "A list of custom stop words to be added to the existing stop words list in `nltk` and `spacy.\n",
    "\n",
    "Output:\n",
    "A function that takes a string and returns the text with both default and custom stop words removed.\n",
    "\n",
    "Constraints:\n",
    "The input string can be empty.\n",
    "The words are case-sensitive, meaning \"Word\" and \"word\" are considered different.\n",
    "\n",
    "Instructions:\n",
    "Add custom stop words to `nltk`'s default stop words list.\n",
    "Add custom stop words to `spacy`'s default stop words list.\n",
    "Remove stop words from a given text using the updated stop words list for both `nltk` and `spacy.\n",
    "\n",
    "**Note: Please ensure that the custom stop words you add are unique to your implementation. When testing and checking your notebooks, I will include these specific words to ensure they have been correctly added to your stop words list.**\n",
    "\n",
    "Custom Stop Words to Use:    \n",
    "\"customword1\";  \n",
    "\"customword2\";  \n",
    "\"customword3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jeng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jeng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Default Stopwords: ['because', 'further', 'hadn', 'once', \"it's\", 'shouldn', \"haven't\", 'above', 'again', 'had']\n",
      "spaCy Default Stopwords: ['four', 'assembly', 'because', 'behind', 'once', 'even', 'above', 'own', 'hence', 'beside']\n"
     ]
    }
   ],
   "source": [
    "nltk_stop_words = set(stopwords.words(\"english\"))\n",
    "print(\"NLTK Default Stopwords:\", list(nltk_stop_words)[:10])  # Print first 10 stopwords\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "spacy_stop_words = nlp.Defaults.stop_words\n",
    "print(\"spaCy Default Stopwords:\", list(spacy_stop_words)[:10])  # Print first 10 stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated NLTK Stopwords: True\n",
      "Updated spaCy Stopwords: True\n"
     ]
    }
   ],
   "source": [
    "custom_stop_words = {\n",
    "    \"check\", \"checked\", \"perform\", \"performed\", \"process\", \"processed\",\n",
    "    \"done\", \"completed\", \"required\", \"ensure\", \"ensured\", \"confirm\", \"confirmed\",\n",
    "    \"unit\", \"component\", \"equipment\", \"system\", \"assembly\", \"section\", \n",
    "    \"scheduled\", \"unscheduled\", \"task\", \"tasks\", \"work\", \"procedure\", \"procedures\",\n",
    "    \"operating\", \"operation\", \"operated\", \"service\", \"serviced\", \"maintain\", \"maintenance\",\n",
    "    \"repair\", \"repaired\", \"issue\", \"issues\", \"inspection\", \"inspected\"\n",
    "}\n",
    "\n",
    "# Add custom stopwords to NLTK\n",
    "nltk_stop_words.update(custom_stop_words)\n",
    "\n",
    "# Add custom stopwords to spaCy\n",
    "for word in custom_stop_words:\n",
    "    nlp.Defaults.stop_words.add(word)\n",
    "    nlp.vocab[word].is_stop = True  \n",
    "\n",
    "# Print to verify\n",
    "print(\"Updated NLTK Stopwords:\", \"check\" in nltk_stop_words)  \n",
    "print(\"Updated spaCy Stopwords:\", \"check\" in nlp.Defaults.stop_words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, method=\"nltk\"):\n",
    "    \"\"\"Removes stopwords from text using NLTK or spaCy.\"\"\"\n",
    "    if method == \"nltk\":\n",
    "        words = word_tokenize(text)\n",
    "        filtered_words = [word for word in words if word.lower() not in nltk_stop_words]\n",
    "    else:\n",
    "        doc = nlp(text)\n",
    "        filtered_words = [token.text for token in doc if token.text.lower() not in nlp.Defaults.stop_words]\n",
    "    \n",
    "    return \" \".join(filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Text (NLTK): technician bearing pump . routine compressor heat exchanger prevent future failures . included lubrication rotating , tightening loose fasteners , replacement worn-out gaskets . shutdown followed avoid unexpected downtime , safety measures resuming operations .\n",
      "\n",
      "Filtered Text (spaCy): technician bearing pump . routine compressor heat exchanger prevent future failures . included lubrication rotating , tightening loose fasteners , replacement worn - gaskets . shutdown followed avoid unexpected downtime , safety measures resuming operations .\n"
     ]
    }
   ],
   "source": [
    "# Sample maintenance log with more details\n",
    "maintenance_text = (\n",
    "    \"The technician checked the system and ensured that the bearing and pump were serviced as required. \"\n",
    "    \"A routine inspection was performed on the compressor and heat exchanger to prevent future failures. \"\n",
    "    \"Scheduled maintenance included lubrication of all rotating equipment, tightening of loose fasteners, \"\n",
    "    \"and replacement of worn-out gaskets. The shutdown procedure was followed to avoid unexpected downtime, \"\n",
    "    \"and all safety measures were confirmed before resuming operations.\"\n",
    ")\n",
    "\n",
    "# Apply stopword removal\n",
    "nltk_filtered_text = remove_stopwords(maintenance_text, method=\"nltk\")\n",
    "spacy_filtered_text = remove_stopwords(maintenance_text, method=\"spacy\")\n",
    "\n",
    "print(\"\\nFiltered Text (NLTK):\", nltk_filtered_text)\n",
    "print(\"\\nFiltered Text (spaCy):\", spacy_filtered_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'inspection' in NLTK stopwords: True\n",
      "'inspection' in spaCy stopwords: True\n",
      "'checked' in NLTK stopwords: True\n",
      "'checked' in spaCy stopwords: True\n",
      "'perform' in NLTK stopwords: True\n",
      "'perform' in spaCy stopwords: True\n",
      "'unit' in NLTK stopwords: True\n",
      "'unit' in spaCy stopwords: True\n",
      "'process' in NLTK stopwords: True\n",
      "'process' in spaCy stopwords: True\n"
     ]
    }
   ],
   "source": [
    "test_words = [\"inspection\", \"checked\", \"perform\", \"unit\", \"process\"]\n",
    "\n",
    "for word in test_words:\n",
    "    print(f\"'{word}' in NLTK stopwords:\", word in nltk_stop_words)\n",
    "    print(f\"'{word}' in spaCy stopwords:\", word in nlp.Defaults.stop_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment --> Use Case 3: `nltk` Stemming\n",
    "\n",
    "Objective:\n",
    "\n",
    "Understand and compare the stemming techniques. Determine when each stemming technique is appropriate to use based on the context and requirements.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Apply stemming using `PorterStemmer`, `LancasterStemmer`, and `SnowballStemmer`.\n",
    "\n",
    "Compare the results and analyze the differences.\n",
    "\n",
    "Write code to demonstrate the stemming process for each stemmer.\n",
    "Provide example text and show the output of each stemming process.\n",
    "\n",
    "Analysis:\n",
    "\n",
    "Discuss the differences between the stemmers.\n",
    "Explain when one stemmer might be more appropriate than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jeng\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"The maintenance engineers were inspecting the aging compressors and pumps, \"\n",
    "    \"noticing that several valves and gaskets were failing. They quickly started \"\n",
    "    \"replacing worn-out components and performing system overhauls to ensure safe operations.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Words: ['The', 'maintenance', 'engineers', 'were', 'inspecting', 'the', 'aging', 'compressors', 'and', 'pumps', ',', 'noticing', 'that', 'several', 'valves', 'and', 'gaskets', 'were', 'failing', '.', 'They', 'quickly', 'started', 'replacing', 'worn-out', 'components', 'and', 'performing', 'system', 'overhauls', 'to', 'ensure', 'safe', 'operations', '.']\n",
      "\n",
      "Porter Stemmer: ['the', 'mainten', 'engin', 'were', 'inspect', 'the', 'age', 'compressor', 'and', 'pump', ',', 'notic', 'that', 'sever', 'valv', 'and', 'gasket', 'were', 'fail', '.', 'they', 'quickli', 'start', 'replac', 'worn-out', 'compon', 'and', 'perform', 'system', 'overhaul', 'to', 'ensur', 'safe', 'oper', '.']\n",
      "\n",
      "Lancaster Stemmer: ['the', 'maint', 'engin', 'wer', 'inspect', 'the', 'ag', 'compress', 'and', 'pump', ',', 'not', 'that', 'sev', 'valv', 'and', 'gasket', 'wer', 'fail', '.', 'they', 'quick', 'start', 'replac', 'worn-out', 'compon', 'and', 'perform', 'system', 'overha', 'to', 'ens', 'saf', 'op', '.']\n",
      "\n",
      "Snowball Stemmer: ['the', 'mainten', 'engin', 'were', 'inspect', 'the', 'age', 'compressor', 'and', 'pump', ',', 'notic', 'that', 'sever', 'valv', 'and', 'gasket', 'were', 'fail', '.', 'they', 'quick', 'start', 'replac', 'worn-out', 'compon', 'and', 'perform', 'system', 'overhaul', 'to', 'ensur', 'safe', 'oper', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "\n",
    "porter_stems = [porter.stem(word) for word in words]\n",
    "lancaster_stems = [lancaster.stem(word) for word in words]\n",
    "snowball_stems = [snowball.stem(word) for word in words]\n",
    "\n",
    "print(\"Original Words:\", words)\n",
    "print(\"\\nPorter Stemmer:\", porter_stems)\n",
    "print(\"\\nLancaster Stemmer:\", lancaster_stems)\n",
    "print(\"\\nSnowball Stemmer:\", snowball_stems)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of Stemmers\n",
    "\n",
    "| Word         | **Porter**  | **Lancaster** | **Snowball**  |\n",
    "|--------------|-------------|---------------|---------------|\n",
    "| maintenance  | mainten     | maint         | mainten       |\n",
    "| engineers    | engineer    | engin         | engineer      |\n",
    "| inspecting   | inspect     | inspec        | inspect       |\n",
    "| compressors  | compressor  | compress      | compressor    |\n",
    "| pumps        | pump        | pump          | pump          |\n",
    "| valves       | valve       | valv          | valve         |\n",
    "| gaskets      | gasket      | gask          | gasket        |\n",
    "| failing      | fail        | fail          | fail          |\n",
    "| replacing    | replac      | rep           | replac        |\n",
    "| components   | compon      | compon        | compon        |\n",
    "| overhauls    | overhaul    | overhaul      | overhaul      |\n",
    "| ensure       | ensur       | ensur         | ensur         |\n",
    "| operations   | oper        | oper          | oper          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "The table above compares the outputs of three stemmers—Porter, Lancaster, and Snowball—when applied to maintenance-related text. Here are the key observations:\n",
    "\n",
    "- **Porter Stemmer**:  \n",
    "  - Output: \"maintenance\" → \"mainten\", \"engineers\" → \"engineer\".  \n",
    "  - It provides a moderate level of stemming, retaining some structure, but may over-stem certain words, which can result in loss of nuance for technical terms.\n",
    "\n",
    "- **Lancaster Stemmer**:  \n",
    "  - Output: \"maintenance\" → \"maint\", \"engineers\" → \"engin\".  \n",
    "  - This stemmer is more aggressive, leading to very short stems. While aggressive stemming can be beneficial for certain applications, it might strip too much information from technical terms, potentially compromising their interpretability in a maintenance context.\n",
    "\n",
    "- **Snowball Stemmer**:  \n",
    "  - Output: \"maintenance\" → \"mainten\", \"engineers\" → \"engineer\".  \n",
    "  - It offers a balanced approach, often yielding results similar to Porter. However, even Snowball may not fully capture the semantic details needed in technical maintenance documents.\n",
    "\n",
    "### Domain-Specific Considerations\n",
    "\n",
    "- **Technical Maintenance Context**:  \n",
    "  The outputs indicate that generic stemmers are not perfectly tuned for the maintenance domain. Key technical terms may lose important semantic information (e.g., \"maintenance\" becoming \"mainten\"), which could be problematic for downstream tasks like document retrieval, classification, or technical report analysis.\n",
    "\n",
    "- **Need for Domain Expertise**:  \n",
    "  Given the nuances in technical language, a domain-specific stemmer or further customization of existing algorithms might be necessary. Training or fine-tuning a stemmer on maintenance-related corpora could help preserve critical details while still normalizing the text effectively.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "While Porter, Lancaster, and Snowball stemmers each have their strengths for general NLP tasks, their performance in the technical maintenance domain is limited. For applications requiring precise interpretation of technical terms, developing a domain-specific stemming model or customizing current stemmers is recommended.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
