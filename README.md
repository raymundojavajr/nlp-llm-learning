# NLP & LLM Learning Repository

This repository documents my learning journey in **Natural Language Processing (NLP)** and **Large Language Models (LLMs)**. It contains structured notes, code, and projects covering various NLP concepts, including tokenization, embeddings, transformers, and fine-tuning.

---

## Repository Structure

- **`sessions/`** – Contains structured learning sessions, organized by topic.  
- **`environment.yml`** – Conda environment file for dependencies.  
- **`README.md`** – Documentation and setup guide.  
- **`test.py`** – Simple test script.  

---

## Topics Covered

- Tokenization & Stopwords  
- Word Embeddings & Vectorization  
- Text Preprocessing Techniques  
- Named Entity Recognition (NER)  
- Transformer Models (BERT, GPT, etc.)  
- Fine-Tuning LLMs for NLP Tasks  

---

## Setup Instructions

### 1. Clone the Repository
```sh
git clone https://github.com/raymundojavajr/nlp-llm-learning.git
cd nlp-llm-learning
```

### 2. Set Up the Conda Environment
```sh
mamba env create -f environment.yml
mamba activate nlp2025a
```

### 3. Run Jupyter Notebook
```sh
jupyter notebook
```

---

## Future Plans

- Expand NLP deep learning experiments.  
- Implement fine-tuning for transformer models.  
- Explore advanced LLM evaluation techniques.  

---

## Contact

For any inquiries or discussions, feel free to reach out:  
**GitHub:** [raymundojavajr](https://github.com/raymundojavajr)  
**LinkedIn:** [linkedin.com/in/raymundojavajr](www.linkedin.com/in/raymundo-java-jr-aba81ba9)  
